{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 1 Linear Regression Example\n",
      "Coefficients: 894.088865711\n",
      "Intercept: 152.939787498\n",
      "MSE: 2602.56278739\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAADuCAYAAAAOR30qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10fe3aed0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sklearn Linear Regression Example\n",
      "Coefficients: [[ 938.23786125]]\n",
      "Intercept: [ 152.91886183]\n",
      "MSE:2548.07239873\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAADuCAYAAAAOR30qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+B+8P3IpCV3ZuwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1134db7d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, linear_model\n",
    "import time\n",
    "\n",
    "\n",
    "def plot_line(x, y, y_hat,line_color='blue'):\n",
    "    # Plot outputs\n",
    "    plt.scatter(x, y,  color='black')\n",
    "    plt.plot(x, y_hat, color=line_color,\n",
    "             linewidth=3)\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def linear_grad_func(theta, x, y):\n",
    "    # TODO compute gradient\n",
    "    # m = x.shape[0]\n",
    "    # h = linear_val_func(theta, x)\n",
    "    # a1 = h - y\n",
    "    # a2 = np.c_[np.ones(x.shape[0]), x]\n",
    "    # temp_multiply = a1 * a2\n",
    "    #\n",
    "    # grad = np.sum(temp_multiply, axis = 0) / m\n",
    "    m = y.size\n",
    "    y_hat = linear_val_func(theta, x)\n",
    "    x = np.c_[np.ones(x.shape[0]), x]\n",
    "    grad = np.sum((y_hat - y) * x, axis = 0) * 1.0 / m\n",
    "    # grad = np.sum((linear_val_func(theta, x) - y) * np.c_[np.ones(x.shape[0]), x], axis = 0) * 1.0 / x.shape[0]\n",
    "    return grad\n",
    "\n",
    "\n",
    "def linear_val_func(theta, x):\n",
    "    # forwarding\n",
    "    return np.dot(np.c_[np.ones(x.shape[0]), x], theta.T)  # return a column\n",
    "\n",
    "\n",
    "def linear_cost_func(theta, x, y):\n",
    "    # TODO compute cost (loss)\n",
    "    m = x.shape[0]\n",
    "    h = linear_val_func(theta, x)\n",
    "    cost = np.sum((h - y) ** 2) / (2 * m)\n",
    "    return cost\n",
    "\n",
    "\n",
    "def linear_grad_desc(theta, X_train, Y_train, lr=0.1, max_iter=10000, converge_change=.001):\n",
    "\n",
    "    cost_iter = []\n",
    "    cost = linear_cost_func(theta, X_train, Y_train)\n",
    "    cost_iter.append([0, cost])\n",
    "    cost_change = 1\n",
    "    i = 1\n",
    "    while cost_change > converge_change and i< max_iter:\n",
    "        pre_cost = cost\n",
    "        # compute gradient\n",
    "        grad = linear_grad_func(theta, X_train, Y_train)\n",
    "\n",
    "        # TODO Update gradient\n",
    "        theta = theta - lr * grad\n",
    "\n",
    "\n",
    "        cost = linear_cost_func(theta, X_train, Y_train)\n",
    "        cost_iter.append([i, cost])\n",
    "        cost_change = abs(cost - pre_cost)\n",
    "        i += 1\n",
    "\n",
    "    return theta, cost_iter\n",
    "\n",
    "\n",
    "def linear_regression():\n",
    "    # load dataset\n",
    "    dataset = datasets.load_diabetes()\n",
    "    # Select only 2 dims\n",
    "    X = dataset.data[:, 2]\n",
    "    Y = dataset.target\n",
    "\n",
    "    # split dataset into training and testing\n",
    "    X_train = X[:-20, None]\n",
    "    X_test = X[-20:, None]\n",
    "\n",
    "    Y_train = Y[:-20, None]\n",
    "    Y_test = Y[-20:, None]\n",
    "\n",
    "\n",
    "    # Linear regression\n",
    "    theta = np.random.rand(1, X_train.shape[1]+1)  # init, 1 x (shape[1] + 1) , 1 x 2, a row\n",
    "    fitted_theta, cost_iter = linear_grad_desc(theta, X_train, Y_train, lr=0.1, max_iter=50000)\n",
    "\n",
    "    print('Coefficients: {}'.format(fitted_theta[0,-1]))\n",
    "    print('Intercept: {}'.format(fitted_theta[0,-2]))\n",
    "    print('MSE: {}'.format(np.sum((linear_val_func(fitted_theta, X_test) - Y_test)**2) / Y_test.shape[0]))\n",
    "    # plt.figure(1)\n",
    "\n",
    "    plot_line(X_test, Y_test, linear_val_func(fitted_theta, X_test))\n",
    "    plt.draw()\n",
    "    time.sleep(5)\n",
    "    plt.close(1)\n",
    "\n",
    "\n",
    "def sklearn_linear_regression():\n",
    "    # load dataset\n",
    "    dataset = datasets.load_diabetes()\n",
    "    # Select only 2 dims\n",
    "    X = dataset.data[:, 2]\n",
    "    Y = dataset.target\n",
    "\n",
    "    # split dataset into training and testing\n",
    "    X_train = X[:-20, None]\n",
    "    X_test = X[-20:, None]\n",
    "\n",
    "    Y_train = Y[:-20, None] # last 20 lines\n",
    "    Y_test = Y[-20:, None]\n",
    "\n",
    "    # Linear regression\n",
    "    regressor = linear_model.LinearRegression()\n",
    "    regressor.fit(X_train, Y_train)\n",
    "    print('Coefficients: {}'.format(regressor.coef_))\n",
    "    print('Intercept: {}'.format(regressor.intercept_))\n",
    "    print('MSE:{}'.format(np.mean((regressor.predict(X_test) - Y_test) ** 2)))\n",
    "\n",
    "    plt.figure(2)\n",
    "    plot_line(X_test, Y_test, regressor.predict(X_test),line_color='red')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def main():\n",
    "    print('Class 1 Linear Regression Example')\n",
    "    linear_regression()\n",
    "\n",
    "    print ('')\n",
    "\n",
    "    print('sklearn Linear Regression Example')\n",
    "    sklearn_linear_regression()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 1 Linear Regression Example\n",
      "Coefficients: 907.024786542\n",
      "Intercept: 152.933656151\n",
      "MSE: 2585.70009399\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAADuCAYAAAAOR30qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x107593810>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sklearn Linear Regression Example\n",
      "Coefficients: [[ 938.23786125]]\n",
      "Intercept: [ 152.91886183]\n",
      "MSE:2548.07239873\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAADuCAYAAAAOR30qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAEGtJREFUeJzt3W+MXFX9x/HPnf7RHaC1UFBjmXuRWClFEFir8RcV/+H/\nJwY1cawx/pkHBEIkoUYm0WgyxOojIfgzQ41R9z5RiSZiTEqtxJhodCskFmEJkZktGkxbwbaZLv0z\n1wens7vd7sy9t90799xz36+kD3Y4W77Nwifffs+553pRFAkAkL9K3gUAAAwCGQAsQSADgCUIZACw\nBIEMAJYgkAHAEgQyAFiCQAYASxDIAGCJ1WkWb9y4MQqCIKNSAMBN+/btOxRF0eVx61IFchAEmp6e\nPv+qAKCEPM/rJlnHyAIALEEgA4AlCGQAsASBDACWIJABwBIEMgCnhWGoIAhUqVQUBIHCMMy7pKFS\nHXsDgCIJw1CNRkO9Xk+S1O121Wg0JEn1ej3P0pZFhwzAWc1mcz6MB3q9nprNZk4VjUYgA3DW7Oxs\nqs/zRiADcFatVkv1ed4IZADOarVaqlarZ31WrVbVarVyqmg0AhmAs+r1utrttnzfl+d58n1f7Xbb\nyg09SfKiKEq8eHJyMuJyIQBIx/O8fVEUTcato0MGAEsQyABgCQIZACxBIAOAJQhkALAEgQwAliCQ\nAcASBDIAWIJABgBLEMgAYAkCGQAsQSADgCUIZACwBIEMAJYgkAHAEgQyAFiCQAYASxDIAGAJAhkA\nLEEgA4AlCGQAsASBDACWIJABwBIEMgBYgkAGAEsQyABgCQIZACxBIAOAJQhkALAEgQwAliCQAcAS\nBDIAWIJABgBLEMgAYAkCGQAsQSADgCUIZACwBIEMAJYgkAHAEgQyAFiCQAYASxDIAGAJAhkALEEg\nA4AlCGQAsASBDACWIJABwBIEMgBYgkAGAEsQyADc9cIL0o03Sp4nXXONND2dd0UjEcgArBSGoYIg\nUKVSURAECsMw+Tf/6lcmhF/7WumJJ8xnMzPSj3+cTbErZHXeBQDAUmEYqtFoqNfrSZK63a4ajYYk\nqV6vL/9NJ05It98u/eAHw3/jYd9rCS+KosSLJycno2nLW34AxRcEgbrd7jmf+76vTqdz9odPPy29\n/e3Siy8O/w2vvlrau1eq1Va20IQ8z9sXRdFk3DpGFgCsMzs7G//5979vxhJbtgwP43vukU6dkp59\nNrcwToORBQDr1Gq1ZTvkrZs2SbfeKj366Ojf4LHHpHe9K5viMkSHDMA6rVZL1Wp1/uv/kxRJ+tuB\nA8PD+D3vMZ1yFBUyjCU6ZAAWqtfr8vp9bf3iF3XDiROjFz/wgHTHHeMpLGMEMgC7PPWUdO21+vSo\nNevWSX/8o3TtteOqaiwYWQCwwze+YTbpRoXs5z4nzc1J//2vc2Es0SEDyNOxY9LGjdLLL49e961v\nSV/5ynhqyhEdMmChC3pKrQh++1vTDV9yyegwnpkxm3QlCGOJQAasM3hKrdvtKoqi+afUCh/KUSR9\n8pMmiN/3vuHr3vlO6fRps37z5vHVZwGe1AMsk+optSL45z+lTZvi1/3sZ9Jtt2VfTw54Ug8oqERP\nqRXBrl2mG44L40OHTDfsaBinQSADlqkNecR32OdWOXnSXHPpedKXvjR83e23mxCOIumyy8ZXn+UI\nZMAyS59Sk6RqtapWq5VTRQk8/rgJ4bVrzUbcMH/6kwnhBx8cX20FQiADlqnX62q32/J9X57nyfd9\ntdvt4ddO5umee0wQ33TT8DW1mjk7HEXSW986vtoKiE09AOm89JK0YUP8uvvvl+68M/t6CiDpph4P\nhgBI5pFHpI99LH7dc89JQZB5OS5iZAFguCiSPvQhM5YYFcYf+YjU75v1hPF5o0MGcK5OR7rqqvh1\njzxiwhgrgg4ZwIL77zfdcFwYv/SS6YYJ4xVFIANld+yYCWHPk+66a/i6HTsWzg6vXz+++kqEQAbK\n6ic/WbjgZ5THHzchvHPneOoqMWbIQNmsWWNe/DnK1q0miNesGU9NkESHDJTDc88tjCVGhfGuXaYb\n3r+fMM4BgQy47O67TQi//vWj1+3fb4L4C18YT11YFiMLwDWnTiXvbvt9E9iwAh0y4IrHHjPhGhfG\n3/3uwmkJwtgqdMhA0W3bJv3lL/HrDh3iqkvLEchAEb34onTppfHrbrhBeuKJ7OvBimBkARTJ975n\nxgxxYbxnjxlJEMaFQocM2C6KpErC3unkSWk1/1sXFR0yYKunnjLdcFwY33nnwiYdYVxo/PQA21x1\nlbltLc6zz0pXX515ORgfAhmwwfHj0pL36A2V4i0/KBZGFkCeBpt0cWH8wx8ujCXgLDpkIA9JH8g4\nfDjZ8TY4gQ55iTAMFQSBKpWKgiBQGIZ5lwRXdDoLF/zEGXTDhHGpEMiLhGGoRqOhbrerKIrU7XbV\naDQIZVyYT30q2Vs4fvlLxhIl50UpfviTk5PR9PR0huXkKwgCdbvdcz73fV+dJLvewECas8OnTkmr\nVmVbD3Lled6+KIom49bRIS8yOzub6nO46YLGVrt3Jzs7/MEPLnTDhDHOYFNvkVqttmyHXKvVcqgG\neRiMrXq9niTNj60kqV6vD//GiQlpbi7+XzAzI23evBKlwkF0yIu0Wi1Vlxw/qlararVaOVWEcWs2\nm/NhPNDr9dRsNs9dfOTIwiZdXBgPumHCGCMQyIvU63W12235vi/P8+T7vtrt9ujOCE5JNLa67z4T\nwnFvXt65k006pEIgL1Gv19XpdNTv99XpdAjjkhk2nqrVagvd8HLd8mJHj5oQ3rEjgwpXHkc97UEg\nA4ssHVtdIymS1Flmb+Esr3rVQjd88cWZ1riSOOppF469AUuEYagtn/+8bjpxIn7x3r3Su9+dfVEZ\n4ajneCQ99sYpC2DgzMtBEw2pHHk5KEc97cLIAnjwwWQvB92+3bmXg46cmWPs6JBRXklDdXZWuvLK\nbGvJSavVOuvctcRRzzzRIaNc/vWv9Bf8OBrGEkc9bUMgoxw++lETwq973eh1X/ta6c4Oc9TTHows\n4LakY4lezzz+DOSIDhnu+cUv0o8lCGNYgA4Z7kjaDe/eLb3//dnWApwHAhnF1utJF12UbG2J5sIo\nJkYWKKZGw3TEcWHs+6XbpENx0SGjWJKOJf7xj/hXJgGWoUOG/Z58Mv0mHWGMAiKQYa9BCF933eh1\nX/0qYwk4gUDOEffQLmNwT0SSbvjll836++7Lvi5gDAjknHAP7RLf/nayl4NKC93w2rXZ1wWMEfch\n54R7aM9Iukm3Z4/03vdmWwuQEe5Dtlyp76E9eFC64opka5kLo0QYWeSklPfQvulNpiOOC+NXv5pN\nOpQSgZyTpe9ukxy+h3awSbd//+h1zz9vQviFF8ZTF2AZAjknzt9Du2dP+rPDcVdjAo5jUw8rK+km\n3b33Si7+bQBYBpt6GJ8zLwdNvHbVqmzrAQqKkQXO3913J3s5qLQwliCMgaHokJFe0rHE738vveMd\n2dYCOIRARjKdTvILeziuBpwXRhYY7cYbTUccF8bbtnF2GLhAdMhYXtKxxH/+I23YkG0tQEnQIWPB\nb36T/uwwYQysGAIZCyH84Q+PXLZdUuD7CqemxlMXUDKMLMpqbk6amEi09KKJCfWOHzdfnLkmVJI7\nTxUClqBDLpsvf9l0w3FhvGGDFEUKfH8hjM/o9XpqNpsZFgmUEx1yWSTdpJuZkTZvnv+y1NeEAmNG\nh+yyZ55Jv0m3KIylkl4TCuSEQHbRZZeZEH7jG0evu+uu2LPDpbomFMgZIwtXRFGy99FJ0vHj0itf\nmWjpYOOu2WxqdnZWtVpNrVaLDT0gA1y/WXRTU9L27cnW8hQdkAuu33Rd0k26X/869nwxADswQy6I\nMAx1Xa2WfpOOMAYKg0AugO7b3qb6Zz6j/QcOjF54/fVc8AMUGCMLm53phP24dQcOSJs2ZV4OgGzR\nIdtm377EY4mK55lumDAGnEAg22IQwpOjN2LvleSd+cXDGYBbGFnkqd9P/I65dRMTOrroTgkezgDc\nQ4ech927TTecJIzPbNL9/0MPyfd9eZ4n3/fVbrd5OANwDIE8Tq94hQniD3xg9Lo//OGc0xL1el2d\nTkf9fl+dTocwjhGGoYIgUKVSURAECsMw75KAWIwssnbkiLR+fbK1HFdbEWEYqtFoqNfrSZK63OGM\ngqBDzkqrZbrhuDD+znc4O7zCms3mfBgPcIczioAOeaUlfaT56FHp4ouzraWkuMMZRUWHvBL+/vdk\nZ4cvvXShGyaMM8MdzigqAvlC3HKLCeGtW0ev27vXhPDhw2Mpa6UVbYOMO5xRVIws0jp1SlqzJtna\nfj/5CMNSRdwg4w5nFBX3ISf1859Ln/hE/LrPflb60Y+yr2dMgiBQt9s953Pf99XpdMZfEFBA3Ie8\nUpJ2uI5e8MMGGTA+zJCXc/Bg+nuHHQxjiQ0yYJwI5MUeesiE8BVXjF63a1dpzg6zQQaMDyMLKflY\nYm7OPP5cImyQAeNT3k29f/9bes1r4tdt2WLOGQPAeUq6qVe+kcXUlOmI48J4ZsaMJCwL46KdCQaQ\nXDlGFqdPS9u2SX/9a/xai+fCRTwTDCA5tzvkJ5803fDq1aPDeGoq1026pF0vl+YAbnOzQ/7616Vv\nfnP0mo0bpdlZaWJiPDUNkabr5Uww4DZ3OuRjx6S1a01HPCqMd+40nfDBg7mHsZSu6+VMMOC24gfy\no4+aEL7kEunkyeHrnnnGBPGOHeOrLYE0XS9nggG3FTOQo0i67TYTxLfeOnzdLbeYDb0okt7whrGV\nl0aarrder6vdbvNuPcBRxQrk5583IVypSA8/PHzdww+bEP7d78xai6Xtenm3HuAuu9NqoN02QXzl\nlaPXHT5sgvjjHx9PXSuArhfAgN1P6s3NxW+83XGH9MAD46kHAM6DG9dv/vSnw//Zn/8sveUt46sF\nADJmdyC/+c3SunXSkSPm6yCQnn66dBf8ACgHuwP5+uvNwxsnTkiXX553NQCQKbsDWZLWr8+7AgAY\ni2KcsgCAEiCQAcASpQ5k7hYGYBP7Z8gZ4W5hALYpbYfM3cIAbFPaQOZuYQC2KW0gc7dwcTH7h6tK\nG8iu3C1ctnAazP673a6iKJqf/bv+50ZJRFGU+NfNN98cuWRqairyfT/yPC/yfT+amprKu6RUpqam\nomq1Gkma/1WtVkf+OYr+Z/Z9/6w/7+CX7/t5lwYMJWk6SpCxdt/2hpGCIFC32z3nc9/31el0zvl8\n6ckSyfytoEjXfVYqFS3336zneer3+zlUBMRLettbaUcWLki7MenCyRJm/3AZgVxgacPJhZMlrsz+\ngeUQyAWWNpxc6C55wwpcRiAXWNpwcqW75L2CcFUhArlsR7vSSBNOdJeA3aw/ZeHCyQAA5ebMKQsX\nTgYAQBLWB7ILJwMAIAnrA9mFkwEAkIT1gezKyQAAiGN1IIdhOD9DXrVqlSRxMqAkOFmDMrL2jSFL\nT1ecPn16vjMmjN3G21xQVtYee0t7cQ7cwc8erin8sTdOV5QXP3uUlbWBzOmK8uJnj7KyNpA5XVFe\n/OxRVtYGMvculBc/e5SVtZt6AOCKwm/qAUDZEMgAYAkCGQAsQSADgCUIZACwRKpTFp7nHZR07jOt\nAIBR/CiKLo9blCqQAQDZYWQBAJYgkAHAEgQyAFiCQAYASxDIAGAJAhkALEEgA4AlCGQAsASBDACW\n+B+8P3IpCV3ZuwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1136ec110>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# coding=utf-8\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, linear_model\n",
    "\n",
    "\n",
    "# 绘图函数\n",
    "def plot_line(x, y, y_hat, line_color='blue'):\n",
    "    # Plot outputs\n",
    "    plt.scatter(x, y,  color='black')\n",
    "    plt.plot(x, y_hat, color=line_color,\n",
    "             linewidth=3)\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# 梯度函数 1/m * sum((y_hat - y) * x)\n",
    "def linear_grad_func(theta, x, y):\n",
    "    # TODO compute gradient\n",
    "    # compute gradient\n",
    "    # np.dot((1 x m), (m x 2))\n",
    "    # 输出: 对于每一个w求偏导，w维度为1 x 2，所以grad维度也应该是1 x 2\n",
    "    # 输出维度: 1 x 2\n",
    "    grad = np.dot((linear_val_func(theta, x) - y).T, np.c_[np.ones(x.shape[0]), x])\n",
    "    grad = grad / x.shape[0]\n",
    "\n",
    "    return grad\n",
    "\n",
    "\n",
    "# 前向传播求值函数 y_hat = wT * x\n",
    "def linear_val_func(theta, x):\n",
    "    # forwarding\n",
    "    # 第一列添加bias 1\n",
    "    # 输出维度: m x 1\n",
    "    return np.dot(np.c_[np.ones(x.shape[0]), x], theta.T)\n",
    "\n",
    "\n",
    "# 损失函数: cost_func = 1/m * sum((y_hat-y)^2)\n",
    "def linear_cost_func(theta, x, y):\n",
    "    # TODO compute cost (loss)\n",
    "    # compute cost (loss)\n",
    "    y_hat = linear_val_func(theta, x)\n",
    "    cost = np.mean((y_hat-y)**2)\n",
    "\n",
    "    return cost\n",
    "\n",
    "\n",
    "# 梯度下降法: theta = theta - alpha * partial_derivative(cost_func)\n",
    "def linear_grad_desc(theta, X_train, Y_train, lr=0.1, max_iter=10000, converge_change=.001):\n",
    "\n",
    "    cost_iter = []\n",
    "    # 先算cost\n",
    "    cost = linear_cost_func(theta, X_train, Y_train)\n",
    "    cost_iter.append([0, cost])\n",
    "    cost_change = 1\n",
    "    i = 1\n",
    "\n",
    "    # 两个判断：1. 如果cost变化满足条件则退出迭代\n",
    "    #          2. 如果迭代次数达到10000次，也退出迭代\n",
    "    while cost_change > converge_change and i < max_iter:\n",
    "        pre_cost = cost\n",
    "        # 再算gradient\n",
    "        # compute gradient: partial_derivative(cost_func)\n",
    "        grad = linear_grad_func(theta, X_train, Y_train)\n",
    "        # update gradient\n",
    "\n",
    "        # TODO Update gradient\n",
    "        # 再乘以学习率，更新梯度\n",
    "        # theta is what we want to train !!!\n",
    "        theta = theta - lr * grad\n",
    "        # model is pre-defined: linear\n",
    "\n",
    "        # 再算cost\n",
    "        # compute loss\n",
    "        cost = linear_cost_func(theta, X_train, Y_train)\n",
    "        cost_iter.append([i, cost])\n",
    "\n",
    "        # 计算cost变化是否满足要求\n",
    "        cost_change = abs(cost - pre_cost)\n",
    "        i += 1\n",
    "\n",
    "    return theta, cost_iter\n",
    "\n",
    "\n",
    "# 线性回归\n",
    "def linear_regression():\n",
    "    # load dataset\n",
    "    dataset = datasets.load_diabetes()\n",
    "    # Select only 2 dims\n",
    "    X = dataset.data[:, 2]\n",
    "    Y = dataset.target\n",
    "\n",
    "    # split dataset into training and testing\n",
    "    X_train = X[:-20, None]\n",
    "    X_test = X[-20:, None]\n",
    "\n",
    "    Y_train = Y[:-20, None]\n",
    "    Y_test = Y[-20:, None]\n",
    "\n",
    "    # Linear regression\n",
    "    theta = np.random.rand(1, X_train.shape[1]+1)\n",
    "    fitted_theta, cost_iter = linear_grad_desc(theta, X_train, Y_train, lr=0.1, max_iter=50000)\n",
    "\n",
    "    print('Coefficients: {}'.format(fitted_theta[0,-1]))\n",
    "    print('Intercept: {}'.format(fitted_theta[0,-2]))\n",
    "    print('MSE: {}'.format(np.sum((linear_val_func(fitted_theta, X_test) - Y_test)**2) / Y_test.shape[0]))\n",
    "\n",
    "    plot_line(X_test, Y_test, linear_val_func(fitted_theta, X_test))\n",
    "\n",
    "\n",
    "# 用sklearn完成线性回归\n",
    "def sklearn_linear_regression():\n",
    "    # load dataset\n",
    "    dataset = datasets.load_diabetes()\n",
    "    # Select only 2 dims\n",
    "    X = dataset.data[:, 2]\n",
    "    Y = dataset.target\n",
    "\n",
    "    # split dataset into training and testing\n",
    "    X_train = X[:-20, None]\n",
    "    X_test = X[-20:, None]\n",
    "\n",
    "    Y_train = Y[:-20, None]\n",
    "    Y_test = Y[-20:, None]\n",
    "\n",
    "    # Linear regression\n",
    "    regressor = linear_model.LinearRegression()\n",
    "    regressor.fit(X_train, Y_train)\n",
    "    print('Coefficients: {}'.format(regressor.coef_))\n",
    "    print('Intercept: {}'.format(regressor.intercept_))\n",
    "    print('MSE:{}'.format(np.mean((regressor.predict(X_test) - Y_test) ** 2)))\n",
    "\n",
    "    plot_line(X_test, Y_test, regressor.predict(X_test), line_color='red')\n",
    "\n",
    "\n",
    "def main():\n",
    "    print('Class 1 Linear Regression Example')\n",
    "    linear_regression()\n",
    "\n",
    "    print ('')\n",
    "\n",
    "    print('sklearn Linear Regression Example')\n",
    "    sklearn_linear_regression()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
