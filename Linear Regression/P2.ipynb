{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the housing and yacht dataset to estimate the regression weights using normal equations. Contrast the performance (measured \n",
    "\n",
    "#### through RMSE) to the results obtained using the gradient descent algorithm, based on a ten-fold cross validation scheme. In this \n",
    "\n",
    "#### problem you will calculate the analytical solution that we obtained through Normal equations to learn your weight vector, and contrast \n",
    "\n",
    "#### the performance (training and test RMSE) for the same fold with your gradient-descent based implementation for problem-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Housing dataset Normal Equation\n",
      "Train RMSE: 4.73601227233\n",
      "Test RMSE: 4.45567333622\n",
      "Train RMSE: 4.75007070269\n",
      "Test RMSE: 4.3291193144\n",
      "Train RMSE: 4.55732987289\n",
      "Test RMSE: 5.9368657932\n",
      "Train RMSE: 4.59350438308\n",
      "Test RMSE: 5.72835767431\n",
      "Train RMSE: 4.84450149131\n",
      "Test RMSE: 3.23421974139\n",
      "Train RMSE: 4.6858984292\n",
      "Test RMSE: 5.00967766154\n",
      "Train RMSE: 4.6331047257\n",
      "Test RMSE: 5.44128495769\n",
      "Train RMSE: 4.74629679641\n",
      "Test RMSE: 4.40096739993\n",
      "Train RMSE: 4.64830483118\n",
      "Test RMSE: 5.28858909461\n",
      "Train RMSE: 4.76091307625\n",
      "Test RMSE: 4.2730793073\n",
      "Overall Mean Train RMSE: 4.6955936581\n",
      "Overall Mean Test RMSE: 4.80978342806\n",
      "Overall Mean Train SSE: 9924.99230709\n",
      "Overall Mean Test SSE: 1187.08140521\n",
      "std of train SSE: 351.973891117\n",
      "std of test SSE: 365.543995648\n",
      "\n",
      "Yacht dataset Normal Equation\n",
      "Train RMSE: 8.61969355408\n",
      "Test RMSE: 11.3306061535\n",
      "Train RMSE: 8.91939250885\n",
      "Test RMSE: 8.8481045397\n",
      "Train RMSE: 8.62119112226\n",
      "Test RMSE: 11.3246136435\n",
      "Train RMSE: 9.00936341546\n",
      "Test RMSE: 7.86710705303\n",
      "Train RMSE: 8.75722115641\n",
      "Test RMSE: 10.2630332426\n",
      "Train RMSE: 9.11478850054\n",
      "Test RMSE: 6.83650517283\n",
      "Train RMSE: 9.0342319678\n",
      "Test RMSE: 7.77915875884\n",
      "Train RMSE: 8.79691514885\n",
      "Test RMSE: 9.96585695996\n",
      "Train RMSE: 9.02044864188\n",
      "Test RMSE: 8.02220929236\n",
      "Train RMSE: 8.90548113864\n",
      "Test RMSE: 8.95423622323\n",
      "Overall Mean Train RMSE: 8.87987271548\n",
      "Overall Mean Test RMSE: 9.11914310396\n",
      "Overall Mean Train SSE: 21297.4835868\n",
      "Overall Mean Test SSE: 2559.73588752\n",
      "std of train SSE: 791.630686179\n",
      "std of test SSE: 819.476829277\n",
      "\n",
      "Concrete dataset Normal Equation\n",
      "Train RMSE: 10.3598145076\n",
      "Test RMSE: 10.3780917027\n",
      "Train RMSE: 10.3582056793\n",
      "Test RMSE: 10.3482088148\n",
      "Train RMSE: 10.3597551143\n",
      "Test RMSE: 10.3499340018\n",
      "Train RMSE: 10.2534092008\n",
      "Test RMSE: 11.252548159\n",
      "Train RMSE: 10.3819458606\n",
      "Test RMSE: 10.2189780113\n",
      "Train RMSE: 10.362330727\n",
      "Test RMSE: 10.3097203057\n",
      "Train RMSE: 10.4019750461\n",
      "Test RMSE: 9.96961051688\n",
      "Train RMSE: 10.3365123553\n",
      "Test RMSE: 10.5696353731\n",
      "Train RMSE: 10.3573127731\n",
      "Test RMSE: 10.3672359652\n",
      "Train RMSE: 10.306492133\n",
      "Test RMSE: 10.8082924484\n",
      "Overall Mean Train RMSE: 10.3477753397\n",
      "Overall Mean Test RMSE: 10.4572255299\n",
      "Overall Mean Train SSE: 99261.3139945\n",
      "Overall Mean Test SSE: 11274.9786807\n",
      "std of train SSE: 754.659695463\n",
      "std of test SSE: 734.512457662\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, linear_model\n",
    "from csv import reader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from random import randrange\n",
    "import operator\n",
    "%matplotlib inline  \n",
    "\n",
    "def linear_grad_func(theta, x, y):\n",
    "    # compute gradient\n",
    "    grad = np.dot((linear_val_func(theta, x) - y).T, np.c_[np.ones(x.shape[0]), x])\n",
    "    grad = grad / x.shape[0]\n",
    "\n",
    "    return grad\n",
    "\n",
    "def linear_val_func(theta, x):\n",
    "    # forwarding\n",
    "    return np.dot(np.c_[np.ones(x.shape[0]), x], theta)\n",
    "\n",
    "\n",
    "def linear_cost_func(theta, x, y):\n",
    "    # compute cost (loss)\n",
    "    y_hat = linear_val_func(theta, x)\n",
    "    cost = np.mean((y_hat-y)**2)\n",
    "    return cost\n",
    "\n",
    "\n",
    "def linear_grad_desc(theta, X_train, Y_train, lr, max_iter, tolerance):\n",
    "    cost_iter = []\n",
    "    cost = linear_cost_func(theta, X_train, Y_train)\n",
    "    RMSE_iter = []\n",
    "    RMSE_iter.append(np.sqrt(np.sum((linear_val_func(theta, X_train) - Y_train)**2) / Y_train.shape[0]))\n",
    "    cost_change = 1\n",
    "    i = 1\n",
    "\n",
    "    while cost_change > tolerance and i < max_iter:\n",
    "        pre_cost = cost\n",
    "        # compute gradient\n",
    "        grad = linear_grad_func(theta, X_train, Y_train)\n",
    "        \n",
    "        # update gradient\n",
    "        theta = theta - lr * grad\n",
    "\n",
    "        # compute loss\n",
    "        cost = linear_cost_func(theta, X_train, Y_train)\n",
    "        RMSE_iter.append(np.sqrt(np.sum((linear_val_func(theta, X_train) - Y_train)**2) / Y_train.shape[0]))\n",
    "        cost_change = abs(cost - pre_cost)\n",
    "        i += 1\n",
    "\n",
    "    return theta, RMSE_iter\n",
    "\n",
    "def load_dataset(filename):\n",
    "    '''Loads an example of market basket transactions from a provided csv file.\n",
    "\n",
    "    Returns: A list (database) of lists (transactions). Each element of a transaction is\n",
    "    an item.\n",
    "    '''\n",
    "    with open(filename, 'r') as dest_f:\n",
    "        data_iter = reader(dest_f, delimiter=',', quotechar='\"')\n",
    "        data = [data for data in data_iter]\n",
    "        data_array = np.asarray(data)\n",
    "\n",
    "    return data_array\n",
    "\n",
    "\n",
    "# Split a dataset into k folds\n",
    "def cross_validation_split(dataset, n_folds):\n",
    "    dataset_split = list()\n",
    "    dataset_copy = list(dataset)\n",
    "    fold_size = int(len(dataset) / n_folds)\n",
    "    for i in range(n_folds):\n",
    "        fold = list()\n",
    "        while len(fold) < fold_size:\n",
    "            index = randrange(len(dataset_copy))\n",
    "            fold.append(dataset_copy.pop(index))\n",
    "        dataset_split.append(fold)\n",
    "    return dataset_split\n",
    "\n",
    "def linear_regression(dataset, n_folds, lr, max_iter, tolerance):\n",
    "    # split dataset into training and testing\n",
    "    dataset_split = cross_validation_split(dataset, n_folds)\n",
    "    RMSE_train = []\n",
    "    RMSE_test = []\n",
    "    SSE_train = []\n",
    "    SSE_test = []\n",
    "    \n",
    "    for i in range(n_folds):\n",
    "        test = np.array(dataset_split[i])\n",
    "        train = list(dataset_split)\n",
    "        train.pop(i)\n",
    "        train = np.array(reduce(operator.add, train))\n",
    "        \n",
    "        # Normalize X_Train\n",
    "        X_train = train[:, :-1]\n",
    "        scaler = StandardScaler().fit(X_train)\n",
    "        X_train = scaler.transform(X_train)\n",
    "        \n",
    "        #Get the mean and std to normalize the test dataset\n",
    "        X_test = test[:, :-1]\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        Y_train = train[:, -1]\n",
    "        Y_test = test[:,-1]\n",
    "        \n",
    "        Y_train = Y_train[:, None]\n",
    "        Y_test = Y_test[:, None]\n",
    "\n",
    "        # Linear regression\n",
    "        #  Initialize the weights for the gradient descent algorithm to all zeros\n",
    "        #theta = np.zeros((1, X_train.shape[1] + 1))\n",
    "        theta = np.random.rand(1, X_train.shape[1] + 1)\n",
    "        fitted_theta, RMSE_iter = linear_grad_desc(theta, X_train, Y_train, lr, max_iter, tolerance)\n",
    "        \n",
    "        # \n",
    "        if i == 0:\n",
    "            plt.figure()\n",
    "            plt.plot(range(len(RMSE_iter)), RMSE_iter) \n",
    "            plt.xlabel('Iteration')\n",
    "            plt.ylabel('RMSE')\n",
    "        \n",
    "        RMSE_test.append(np.sqrt(np.sum((linear_val_func(fitted_theta, X_test) - Y_test)**2) / Y_test.shape[0]))\n",
    "        RMSE_train.append(np.sqrt(np.sum((linear_val_func(fitted_theta, X_train) - Y_train)**2) / Y_train.shape[0]))\n",
    "        SSE_test.append(np.sum((linear_val_func(fitted_theta, X_test) - Y_test)**2))\n",
    "        SSE_train.append(np.sum((linear_val_func(fitted_theta, X_train) - Y_train)**2))\n",
    "        print('Train RMSE: {}'.format(RMSE_train[i]))\n",
    "        print('Test RMSE: {}'.format(RMSE_test[i]))\n",
    "    print('Overall Mean Train RMSE: {}'.format(np.sum(RMSE_train)*1./len(RMSE_train)))\n",
    "    print('Overall Mean Test RMSE: {}'.format(np.sum(RMSE_test)*1. / len(RMSE_test)))\n",
    "    print('Overall Mean Train SSE: {}'.format(np.sum(SSE_train)*1./len(SSE_train)))\n",
    "    print('Overall Mean Test SSE: {}'.format(np.sum(SSE_test)*1. / len(SSE_test)))\n",
    "    print('std of train SSE: {}'.format(np.std(np.array(SSE_train), axis=0)))\n",
    "    print('std of test SSE: {}'.format(np.std(np.array(SSE_test), axis=0)))\n",
    "    \n",
    "    \n",
    "def normal_equation(X, y):\n",
    "    # add bias to x\n",
    "    X_b = np.c_[np.ones(X.shape[0]), X]\n",
    "    return np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y)\n",
    "\n",
    "def normal_equation_eval(dataset, n_folds):\n",
    "    dataset_split = cross_validation_split(dataset, n_folds)\n",
    "    RMSE_train = []\n",
    "    RMSE_test = []\n",
    "    SSE_train = []\n",
    "    SSE_test = []\n",
    "    \n",
    "    for i in range(n_folds):\n",
    "        test = np.array(dataset_split[i])\n",
    "        train = list(dataset_split)\n",
    "        train.pop(i)\n",
    "        train = np.array(reduce(operator.add, train))\n",
    "        \n",
    "        # Normalize X_Train\n",
    "        X_train = train[:, :-1]\n",
    "        scaler = StandardScaler().fit(X_train)\n",
    "        X_train = scaler.transform(X_train)\n",
    "        \n",
    "        #Get the mean and std to normalize the test dataset\n",
    "        X_test = test[:, :-1]\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        Y_train = train[:, -1]\n",
    "        Y_test = test[:,-1]\n",
    "        \n",
    "        Y_train = Y_train[:, None]\n",
    "        Y_test = Y_test[:, None]\n",
    "\n",
    "        # Linear regression\n",
    "        #  Initialize the weights for the gradient descent algorithm to all zeros\n",
    "        fitted_theta = normal_equation(X_train, Y_train)\n",
    "        RMSE_test.append(np.sqrt(np.sum((linear_val_func(fitted_theta, X_test) - Y_test)**2) / Y_test.shape[0]))\n",
    "        RMSE_train.append(np.sqrt(np.sum((linear_val_func(fitted_theta, X_train) - Y_train)**2) / Y_train.shape[0]))\n",
    "        SSE_test.append(np.sum((linear_val_func(fitted_theta, X_test) - Y_test)**2))\n",
    "        SSE_train.append(np.sum((linear_val_func(fitted_theta, X_train) - Y_train)**2))\n",
    "        print('Train RMSE: {}'.format(RMSE_train[i]))\n",
    "        print('Test RMSE: {}'.format(RMSE_test[i]))\n",
    "    print('Overall Mean Train RMSE: {}'.format(np.sum(RMSE_train)*1./len(RMSE_train)))\n",
    "    print('Overall Mean Test RMSE: {}'.format(np.sum(RMSE_test)*1. / len(RMSE_test)))\n",
    "    print('Overall Mean Train SSE: {}'.format(np.sum(SSE_train)*1./len(SSE_train)))\n",
    "    print('Overall Mean Test SSE: {}'.format(np.sum(SSE_test)*1. / len(SSE_test)))\n",
    "    print('std of train SSE: {}'.format(np.std(np.array(SSE_train), axis=0)))\n",
    "    print('std of test SSE: {}'.format(np.std(np.array(SSE_test), axis=0)))\n",
    "    \n",
    "\n",
    "def main():\n",
    "    dataset = load_dataset(\"housing.csv\")\n",
    "    dataset = dataset.astype(float)\n",
    "    \n",
    "    print('Housing dataset Normal Equation')\n",
    "    normal_equation_eval(dataset, n_folds=10)\n",
    "    print ('')\n",
    "    \n",
    "    dataset = load_dataset(\"yachtData.csv\")\n",
    "    dataset = dataset.astype(float)\n",
    "    print('Yacht dataset Normal Equation')\n",
    "    normal_equation_eval(dataset, n_folds=10)\n",
    "    print ('')\n",
    "    \n",
    "    dataset = load_dataset(\"concreteData.csv\")\n",
    "    dataset = dataset.astype(float) \n",
    "    print('Concrete dataset Normal Equation')\n",
    "    normal_equation_eval(dataset, n_folds=10)\n",
    "    print ('')\n",
    "    \n",
    "#    print('sklearn Linear Regression Example')\n",
    "#    sklearn_linear_regression(dataset, n_folds=10)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
